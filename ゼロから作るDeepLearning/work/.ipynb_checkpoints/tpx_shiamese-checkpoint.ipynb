{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funny-perfume",
   "metadata": {},
   "source": [
    "Siamese_tpxtech　テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-georgia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optional-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def get_dataset_slice_paths(image_dir, k):\n",
    "  '''\n",
    "  画像のパスリストを返す\n",
    "  '''\n",
    "  image_file_list = os.listdir(image_dir + k)\n",
    "  image_paths = [os.path.join(image_dir+k, fname) for fname in image_file_list]\n",
    "\n",
    "  return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class_word = ['dust', 'friction', 'hair', 'pinhole']\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "for i, k in enumerate(class_word):\n",
    "    training_image_paths = get_dataset_slice_paths('./tpxtech/', k)\n",
    "    # 画像ペアを6チャンネルとして合わせる\n",
    "    cnt = 0\n",
    "    for j in range(0, len(training_image_paths), 2):\n",
    "        im = np.array(Image.open(training_image_paths[j]))\n",
    "        im2 = np.array(Image.open(training_image_paths[j + 1]))\n",
    "        im_concat = np.concatenate([im, im2], 2)\n",
    "        im_concat = im_concat.tolist()\n",
    "        train_data.append(im_concat)\n",
    "        cnt += 1\n",
    "    train_label.extend([i for m in range(cnt)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handmade-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((952, 80, 80, 6), (952,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = np.array(train_data)\n",
    "# train_label = np.array(train_label)\n",
    "# train_data.shape, train_label.shape\n",
    "train_data = np.array(train_data)\n",
    "train_label = np.array(train_label)\n",
    "train_data.shape,  train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "consolidated-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ペアの生成\n",
    "\n",
    "def make_pairs(images, labels):\n",
    "    pairImage = []\n",
    "    pairLabel = []\n",
    "    CLASS = 4\n",
    "    label_idx = [np.where(labels == i)[0] for i in range(CLASS)]\n",
    "    \n",
    "    for idx in range(len(images)):\n",
    "        current = images[idx]\n",
    "        label = labels[idx]\n",
    "        \n",
    "        # ポジティブ\n",
    "        idx_posi = np.random.choice(label_idx[label])\n",
    "        img_posi = images[idx_posi]\n",
    "        pairImage.append([current, img_posi])\n",
    "        pairLabel.append([1])\n",
    "        \n",
    "        # ネガティブ\n",
    "        neg = np.where(labels != label)[0]\n",
    "        idx_neg = np.random.choice(neg)\n",
    "        img_neg = images[idx_neg]\n",
    "        pairImage.append([current, img_neg])\n",
    "        pairLabel.append([0])\n",
    "        \n",
    "    # ランダムに並び替える\n",
    "    per = np.random.permutation(np.arange(len(images)*2))\n",
    "    pairImage = np.array(pairImage)\n",
    "    pairImage = pairImage[per]\n",
    "    \n",
    "    pairLabel = np.array(pairLabel)\n",
    "    pairLabel = pairLabel[per]\n",
    "    \n",
    "    # テスト、バリデーションに分割して返す\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xData_train, xData_test, yData_train, yData_test = train_test_split(pairImage, pairLabel, test_size=0.2)\n",
    "    \n",
    "    return (xData_train, xData_test, yData_train, yData_test)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "xData_train, xData_test, yData_train, yData_test = make_pairs(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dietary-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1523, 2, 80, 80, 6), (381, 2, 80, 80, 6), (1523, 1), (381, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xData_train.shape, xData_test.shape, yData_train.shape, yData_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graphic-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for model\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, Dense, Dropout,GlobalAveragePooling2D, MaxPool2D\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approximate-pleasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                3120      \n",
      "=================================================================\n",
      "Total params: 19,888\n",
      "Trainable params: 19,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_siamese_model(input_shape, output_dim=48):\n",
    "    inputs = Input(input_shape)\n",
    "    x = Conv2D(64, (2,2), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(64, (2,2), padding='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    pooled_output = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(output_dim)(pooled_output)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_siamese_model((28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cutting-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# １つのインスタンスを共有することでパラメータを共有する\n",
    "IMG_SHAPE = (80, 80, 6)\n",
    "\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "\n",
    "feature_extractor = build_siamese_model(IMG_SHAPE)\n",
    "modelA = feature_extractor(imgA)\n",
    "modelB = feature_extractor(imgB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "universal-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユークリッド距離を計算する関数\n",
    "# レイヤとして埋め込むためにkerasで関数を生成する\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    (A, B) = vectors\n",
    "    sumSquared = K.sum(K.square(A - B), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
    "\n",
    "\n",
    "dist = Lambda(euclidean_distance)([modelA, modelB])\n",
    "outputs = Dense(1, activation='sigmoid')(dist)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gothic-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 80, 80, 6)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 80, 80, 6)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 48)           21168       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           model_1[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 21,170\n",
      "Trainable params: 21,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "infectious-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y, preds, margin=1):\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y*squaredPreds + (1 - y)*squaredMargin)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unavailable-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0に近い方場合同一として判定\n",
    "\n",
    "def dist_accuracy(y, preds):\n",
    "    return K.mean(K.equal(y, K.cast(preds < 0.5, y.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "concrete-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_crossentropyの方が簡単に試せる\n",
    "model.compile(\n",
    "    loss = contrastive_loss,\n",
    "    optimizer = 'adam',\n",
    "    metrics = [dist_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "median-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training(history, plot_path):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='train loss')\n",
    "    plt.plot(history.history['val_loss'], label='val loss')\n",
    "    plt.plot(history.history['dist_accuracy'], label='train acc')\n",
    "    plt.plot(history.history['val_dist_accuracy'], label='val_acc')\n",
    "    plt.legend(loc = 'lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "administrative-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     [xData_train[:,0], xData_train[:,1]], yData_train[:],\n",
    "#     validation_data=([xData_test[:,0], xData_test[:,1]], yData_test[:]),\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     epochs = 5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "finnish-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 80, 80, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot_training(history, PLOT_PATH)\n",
    "xData_train[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-ukraine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
